I am an AI-infra SWE at [Megvii Inc](https://en.megvii.com/), working on developing large-scale distributed storage systems.

<table width="960px">
<tr>
<td valign="top" width="50%">

#### <a href="https://www.kongjun18.me" target="_blank">Recent Blog</a>

<!-- BLOG-POST-LIST:START -->
- [[Paper Note] H2O Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](https://kongjun18.github.io/posts/h2o-heavy-hitter-oracle-for-efficient-generative-inference-of-large-language-models/)
- [[Paper Note] Sparse indexing Large scale, inline deduplication using sampling and locality](https://kongjun18.github.io/posts/sparse-indexing-large-scale-inline-deduplication-using-sampling-and-locality/)
- [[Paper Note] IMPRESS An Importance-Informed Multi-Tier Prefix KV Storage System for Large Language Model Inference](https://kongjun18.github.io/posts/impress-an-importance-informed-multi-tier-prefix-kv-storage-system-for-large-language-model-inference/)
- [[Paper Note] Attentionstore Cost-effective attention reuse across multi-turn conversations in large language model serving](https://kongjun18.github.io/posts/attentionstore-cost-effective-attention-reuse-across-multi-turn-conversations-in-large-language-model-serving/)
- [[Paper Note] Orca A Distributed Serving System for Transformer-Based Generative Models](https://kongjun18.github.io/posts/orca-a-distributed-serving-system-for-transformer-based-generative-models/)
<!-- BLOG-POST-LIST:END -->

</td>
<td valign="top" width="50%">

#### Weekly Development Breakdown

<!--START_SECTION:waka-->

```txt
From: 22 September 2025 - To: 29 September 2025

Total Time: 4 hrs 18 mins

C          4 hrs 10 mins   ████████████████████████▒   97.18 %
C++        5 mins          ▓░░░░░░░░░░░░░░░░░░░░░░░░   02.26 %
Assembly   1 min           ░░░░░░░░░░░░░░░░░░░░░░░░░   00.45 %
Text       0 secs          ░░░░░░░░░░░░░░░░░░░░░░░░░   00.07 %
Other      0 secs          ░░░░░░░░░░░░░░░░░░░░░░░░░   00.04 %
```

<!--END_SECTION:waka-->
</td>
</tr>

</table>
