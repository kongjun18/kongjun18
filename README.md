I am an AI-infra SWE at [Megvii Inc](https://en.megvii.com/), working on developing large-scale distributed storage systems.

<table width="960px">
<tr>
<td valign="top" width="50%">

#### <a href="https://www.kongjun18.me" target="_blank">Recent Blog</a>

<!-- BLOG-POST-LIST:START -->
- [[Paper Note] Fast State Restoration in LLM Serving with HCache](https://kongjun18.github.io/posts/fast-state-restoration-in-llm-serving-with-hcache/)
- [[Paper Note] H2O Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](https://kongjun18.github.io/posts/h2o-heavy-hitter-oracle-for-efficient-generative-inference-of-large-language-models/)
- [[Paper Note] Sparse indexing Large scale, inline deduplication using sampling and locality](https://kongjun18.github.io/posts/sparse-indexing-large-scale-inline-deduplication-using-sampling-and-locality/)
- [[Paper Note] IMPRESS An Importance-Informed Multi-Tier Prefix KV Storage System for Large Language Model Inference](https://kongjun18.github.io/posts/impress-an-importance-informed-multi-tier-prefix-kv-storage-system-for-large-language-model-inference/)
- [[Paper Note] Attentionstore Cost-effective attention reuse across multi-turn conversations in large language model serving](https://kongjun18.github.io/posts/attentionstore-cost-effective-attention-reuse-across-multi-turn-conversations-in-large-language-model-serving/)
<!-- BLOG-POST-LIST:END -->

</td>
<td valign="top" width="50%">

#### Weekly Development Breakdown

<!--START_SECTION:waka-->

```txt
From: 20 October 2025 - To: 27 October 2025

Total Time: 2 hrs 34 mins

C++        1 hr 45 mins    █████████████████░░░░░░░░   68.62 %
Docker     19 mins         ███▒░░░░░░░░░░░░░░░░░░░░░   12.67 %
Bash       15 mins         ██▓░░░░░░░░░░░░░░░░░░░░░░   10.36 %
Markdown   8 mins          █▒░░░░░░░░░░░░░░░░░░░░░░░   05.83 %
Makefile   3 mins          ▓░░░░░░░░░░░░░░░░░░░░░░░░   02.21 %
CMake      0 secs          ░░░░░░░░░░░░░░░░░░░░░░░░░   00.30 %
```

<!--END_SECTION:waka-->
</td>
</tr>

</table>
